'use client';

import { WebRTCPeerConfig } from './webrtcTypes';
import { useFileTransferCore } from './useFileTransferCore';
import { FileTransferProgress } from './useTransferProgress';

export interface FileTransferApi {
  // Host methods
  sendFile: (file: File, clientId?: string) => Promise<void>;
  cancelTransfer: (transferId?: string) => void;
  
  // Client methods
  receivedFile: Blob | null;
  receivedFileName: string | null;
  receivedFileHandle: FileSystemFileHandle | null;
  
  // Common
  transferProgress: FileTransferProgress | null;
  isTransferring: boolean;
  clearTransfer: () => void;
  
  // Progress callbacks
  onProgress?: (progress: FileTransferProgress) => void;
  onComplete?: (file: Blob | null, fileName: string | null) => void;
  onError?: (error: string) => void;
  
  // WebRTC connection methods
  connectionState: RTCPeerConnectionState;
  dataChannelState: RTCDataChannelState | undefined;
  createOrEnsureConnection: () => Promise<void>;
  close: () => void;
  disconnect: () => void;
  role: 'host' | 'client';
  peerId?: string;
  connectedClients?: string[];
  clientConnections?: Map<string, { connectionState: RTCPeerConnectionState; dataChannelState: RTCDataChannelState | undefined }>;
}

// Re-export types for backward compatibility
export { FileTransferProgress } from './useTransferProgress';

export function useFileTransfer(config: WebRTCPeerConfig & { 
  debug?: boolean;
  onProgress?: (progress: FileTransferProgress) => void;
  onComplete?: (file: Blob | null, fileName: string | null) => void;
  onError?: (error: string) => void;
}): FileTransferApi {
  const [transferProgress, setTransferProgress] = useState<FileTransferProgress | null>(null);
  const [isTransferring, setIsTransferring] = useState(false);
  const [receivedFile, setReceivedFile] = useState<Blob | null>(null);
  const [receivedFileName, setReceivedFileName] = useState<string | null>(null);
  const [receivedFileHandle, setReceivedFileHandle] = useState<FileSystemFileHandle | null>(null);
  
  // Create logger instance
  const logger = createLogger(config.role, config.debug);
  
  // File System Access API writers for large files
  const streamingWritersRef = useRef<Map<string, FileSystemWritableFileStream>>(new Map());
  const streamingChunksRef = useRef<Map<string, { chunks: Uint8Array[], totalChunks: number, receivedChunks: number }>>(new Map());
  const fileResolversRef = useRef<Map<string, { resolve: (blob: Blob) => void; reject: (error: Error) => void }>>(new Map());
  const streamingMetadataRef = useRef<Map<string, { fileName: string; fileSize: number; transferId: string }>>(new Map());
  
  // Binary chunk handling state
  const pendingChunkMetadataRef = useRef<{ chunkIndex: number; totalChunks: number; transferId: string } | null>(null);
  
  // Throttling for progress updates
  const lastProgressUpdateRef = useRef<number>(0);
  const PROGRESS_UPDATE_THROTTLE = 100; // Update at most every 100ms
  
  // Retry mechanism state
  const retryQueueRef = useRef<Map<string, { chunkIndex: number; retryCount: number; maxRetries: number }>>(new Map());
  const MAX_RETRIES = 3;
  const RETRY_DELAY = 1000; // 1 second delay between retries

  // Check if File System Access API is supported
  const hasFileSystemAccess = useCallback(() => {
    return typeof window !== 'undefined' && 'showSaveFilePicker' in window;
  }, []);

  // Throttled progress update function with callbacks
  const updateProgressThrottled = useCallback((updateFn: (prev: FileTransferProgress | null) => FileTransferProgress | null) => {
    const now = Date.now();
    if (now - lastProgressUpdateRef.current >= PROGRESS_UPDATE_THROTTLE) {
      const newProgress = updateFn(transferProgress);
      setTransferProgress(newProgress);
      lastProgressUpdateRef.current = now;
      
      // Call progress callback
      if (newProgress && config.onProgress) {
        config.onProgress(newProgress);
      }
    }
  }, [transferProgress, config.onProgress]);

  // Retry mechanism functions
  const addToRetryQueue = useCallback((transferId: string, chunkIndex: number) => {
    const retryKey = `${transferId}-${chunkIndex}`;
    const existing = retryQueueRef.current.get(retryKey);
    
    if (existing) {
      existing.retryCount++;
    } else {
      retryQueueRef.current.set(retryKey, {
        chunkIndex,
        retryCount: 1,
        maxRetries: MAX_RETRIES
      });
    }
    
    logger.log(`Added chunk ${chunkIndex} to retry queue (attempt ${existing ? existing.retryCount : 1}/${MAX_RETRIES})`);
  }, [logger]);

  const removeFromRetryQueue = useCallback((transferId: string, chunkIndex: number) => {
    const retryKey = `${transferId}-${chunkIndex}`;
    retryQueueRef.current.delete(retryKey);
  }, []);

  const handleFileChunk = useCallback(async (data: string | ArrayBuffer | Blob) => {
    console.log(`[FileTransfer ${config.role}] Received data:`, typeof data, data instanceof ArrayBuffer ? `ArrayBuffer(${data.byteLength})` : data instanceof Blob ? `Blob(${data.size})` : data);
    
    // Handle binary messages (ArrayBuffer)
    if (data instanceof ArrayBuffer) {
      const binaryMessage = decodeBinaryMessage(data);
      if (!binaryMessage) {
        console.error(`[FileTransfer ${config.role}] Failed to decode binary message`);
        return;
      }
      
      console.log(`[FileTransfer ${config.role}] Decoded binary message:`, {
        type: binaryMessage.type,
        transferId: binaryMessage.transferId,
        dataLength: binaryMessage.data.length
      });
      
      // Handle different binary message types
      if (binaryMessage.type === MESSAGE_TYPES.FILE_START) {
        // Parse file start metadata from binary data
        const metadata = JSON.parse(new TextDecoder().decode(binaryMessage.data));
        const { fileName, fileSize, transferId } = metadata;
        console.log(`[FileTransfer ${config.role}] File transfer started (binary):`, { fileName, fileSize, transferId });
        
        // Validate fileSize
        if (typeof fileSize !== 'number' || fileSize <= 0) {
          console.error(`[FileTransfer ${config.role}] Invalid fileSize:`, fileSize);
          setTransferProgress(prev => prev ? { ...prev, status: 'error', error: 'Invalid file size' } : null);
          return;
        }
        
        console.log(`[FileTransfer ${config.role}] Creating transferProgress with fileName: ${fileName}`);
        setTransferProgress({
          fileName,
          fileSize,
          bytesTransferred: 0,
          percentage: 0,
          status: 'transferring'
        });
        console.log(`[FileTransfer ${config.role}] Setting receivedFileName to: ${fileName}`);
        setReceivedFileName(fileName);
        
        // Store filename for later use (in case transferProgress becomes null)
        if (config.role === 'client') {
          streamingMetadataRef.current.set(transferId, { fileName, fileSize, transferId });
        }
        
        // Calculate total chunks from file size
        const totalChunks = Math.ceil(fileSize / STREAM_CHUNK_SIZE);
        
        // Initialize streaming state
        streamingChunksRef.current.set(transferId, {
          chunks: new Array(totalChunks),
          totalChunks: totalChunks,
          receivedChunks: 0
        });
        
        console.log(`[FileTransfer ${config.role}] Initialized streaming state (binary):`, {
          transferId,
          fileSize,
          totalChunks,
          chunkSize: STREAM_CHUNK_SIZE
        });
        
        // For client, set up storage based on file size and browser support
        if (config.role === 'client') {
          const isLargeFile = fileSize >= LARGE_FILE_THRESHOLD;
          const hasFS = hasFileSystemAccess();
          
          if (isLargeFile) {
            if (hasFS) {
              try {
                console.log(`[FileTransfer Client] Large file detected (${Math.round(fileSize / 1024 / 1024)}MB), using File System Access API`);
                console.log(`[FileTransfer Client] Original filename: ${fileName}`);
                const fileHandle = await (window as any).showSaveFilePicker({
                  suggestedName: fileName,
                  types: [{
                    description: 'All Files',
                    accept: { '*/*': [] }
                  }]
                });
                console.log(`[FileTransfer Client] File handle name: ${fileHandle.name}`);
                
                const writable = await fileHandle.createWritable();
                streamingWritersRef.current.set(transferId, writable);
                console.log(`[FileTransfer Client] Created file handle for streaming large file`);
              } catch (error) {
                console.error(`[FileTransfer Client] User cancelled file save or error:`, error);
                // Send error back to host
                return;
              }
            } else {
              // Warn user about memory usage
              const sizeInMB = Math.round(fileSize / 1024 / 1024);
              const proceed = confirm(`Large file detected (${sizeInMB}MB). This will use significant RAM as your browser doesn't support direct disk streaming. Continue?`);
              if (!proceed) {
                console.log(`[FileTransfer Client] User cancelled large file transfer`);
                return;
              }
              console.log(`[FileTransfer Client] User accepted large file transfer to memory`);
            }
          } else {
            console.log(`[FileTransfer Client] Small file (${Math.round(fileSize / 1024)}KB), using memory storage`);
          }
        }
        return;
      }
      
      if (binaryMessage.type === MESSAGE_TYPES.FILE_ERROR) {
        const errorMessage = new TextDecoder().decode(binaryMessage.data);
        console.error(`[FileTransfer ${config.role}] File transfer error (binary):`, { transferId: binaryMessage.transferId, error: errorMessage });
        setTransferProgress(prev => prev ? { ...prev, status: 'error', error: errorMessage } : null);
        return;
      }
      
      console.warn(`[FileTransfer ${config.role}] Unknown binary message type:`, binaryMessage.type);
      return;
    }
    
    // Handle raw binary data (chunk data without metadata)
    if (data instanceof Blob) {
      // This is raw binary data, check if we have pending metadata
      const pendingMetadata = pendingChunkMetadataRef.current;
      
      if (pendingMetadata) {
        console.log(`[FileTransfer ${config.role}] Processing raw binary chunk data with pending metadata:`, {
          chunkIndex: pendingMetadata.chunkIndex,
          totalChunks: pendingMetadata.totalChunks,
          dataLength: data.size,
          dataType: 'Blob'
        });
        
        // Process the chunk data
        const arrayBuffer = await data.arrayBuffer();
        const chunkUint8 = new Uint8Array(arrayBuffer);
        
        const streamingState = streamingChunksRef.current.get(pendingMetadata.transferId);
        
        if (streamingState) {
          // Check if this chunk was already received
          const wasAlreadyReceived = streamingState.chunks[pendingMetadata.chunkIndex] !== undefined;
          
          streamingState.chunks[pendingMetadata.chunkIndex] = chunkUint8;
          streamingState.totalChunks = pendingMetadata.totalChunks;
          
          console.log(`[FileTransfer ${config.role}] Binary chunk processing:`, {
            chunkIndex: pendingMetadata.chunkIndex,
            totalChunks: pendingMetadata.totalChunks,
            receivedChunks: streamingState.receivedChunks,
            wasAlreadyReceived,
            chunksArrayLength: streamingState.chunks.length
          });
          
          // Write chunk directly to file system (client only, for large files)
          if (config.role === 'client') {
            const writer = streamingWritersRef.current.get(pendingMetadata.transferId);
            
            if (writer) {
              try {
                await writer.write(chunkUint8);
                console.log(`[FileTransfer Client] Wrote chunk ${pendingMetadata.chunkIndex + 1} to disk (File System Access)`);
              } catch (error) {
                console.error(`[FileTransfer Client] Failed to write chunk:`, error);
              }
            }
          }
          
          // Increment received chunks counter
          if (!wasAlreadyReceived) {
            streamingState.receivedChunks++;
            console.log(`[FileTransfer ${config.role}] Incremented receivedChunks to ${streamingState.receivedChunks}/${streamingState.totalChunks}`);
          }
          
          // Update progress (throttled)
          updateProgressThrottled(prev => {
            if (!prev) return null;
            const chunkSize = chunkUint8.length;
            const newBytesTransferred = prev.bytesTransferred + chunkSize;
            const percentage = Math.round((newBytesTransferred / prev.fileSize) * 100);
            
            return {
              ...prev,
              bytesTransferred: newBytesTransferred,
              percentage
            };
          });
          
          // Check completion
          console.log(`[FileTransfer ${config.role}] Binary completion check:`, {
            receivedChunks: streamingState.receivedChunks,
            totalChunks: streamingState.totalChunks,
            isComplete: streamingState.receivedChunks === streamingState.totalChunks,
            chunkIndex: pendingMetadata.chunkIndex,
            isLastChunk: pendingMetadata.chunkIndex === pendingMetadata.totalChunks - 1
          });
          
          if (streamingState.receivedChunks === streamingState.totalChunks) {
            console.log(`[FileTransfer ${config.role}] All chunks received (binary), finalizing file...`);
            console.log(`[FileTransfer ${config.role}] Binary completion details:`, {
              receivedChunks: streamingState.receivedChunks,
              totalChunks: streamingState.totalChunks,
              transferId: pendingMetadata.transferId,
              role: config.role
            });
            
                          if (config.role === 'client') {
                            const writer = streamingWritersRef.current.get(pendingMetadata.transferId);
                            
                            if (writer) {
                              await writer.close();
                              streamingWritersRef.current.delete(pendingMetadata.transferId);
                              console.log(`[FileTransfer Client] File saved to disk via File System Access API`);
                              
                              // Create a File object from the handle to pass to the onComplete callback
                              const fileHandle = receivedFileHandle;
                              if (fileHandle) {
                                const file = await fileHandle.getFile();
                                setReceivedFile(file);
                              }
                            } else {
                              // For small files or unsupported browsers, create blob from chunks
                              const allChunks = streamingState.chunks.filter(chunk => chunk !== undefined);
                              // Try to preserve original MIME type from filename
                              const mimeType = getMimeType(transferProgress?.fileName || '');
                              const fileBlob = new Blob(allChunks as BlobPart[], { type: mimeType });
                              setReceivedFile(fileBlob);
                              console.log(`[FileTransfer Client] File assembled in memory`);
                            }
                          }            
            streamingChunksRef.current.delete(pendingMetadata.transferId);
            
            // Ensure we have valid transferProgress before creating completedProgress
            if (transferProgress) {
              console.log(`[FileTransfer ${config.role}] transferProgress exists, fileName: ${transferProgress.fileName}`);
              const completedProgress = { ...transferProgress, status: 'completed' as const };
              setTransferProgress(completedProgress);
              
              // Set received file state for UI (for binary streaming)
              if (config.role === 'client') {
                console.log(`[FileTransfer Client] Setting receivedFileName from completedProgress: ${completedProgress.fileName}`);
                setReceivedFileName(completedProgress.fileName || 'received_file');
                setReceivedFileHandle(null); // File was saved to disk, not in memory
              }
            } else {
              // transferProgress is null, use stored metadata as fallback
              if (config.role === 'client') {
                const storedMetadata = streamingMetadataRef.current.get(pendingMetadata.transferId);
                if (storedMetadata?.fileName) {
                  console.log(`[FileTransfer Client] Using stored metadata fileName: ${storedMetadata.fileName}`);
                  setReceivedFileName(storedMetadata.fileName);
                } else if (pendingMetadata.fileName) {
                  console.log(`[FileTransfer Client] Using pendingMetadata fileName: ${pendingMetadata.fileName}`);
                  setReceivedFileName(pendingMetadata.fileName);
                }
              }
            }
            
            // Call completion callback
            if (config.onComplete) {
              config.onComplete(receivedFile, receivedFileName);
            }
          }
          
          // Remove pending metadata
          pendingChunkMetadataRef.current = null;
        } else {
          console.error(`[FileTransfer ${config.role}] No streaming state found for transfer ${pendingMetadata.transferId}`);
        }
      } else {
        console.warn(`[FileTransfer ${config.role}] Received raw binary data but no pending metadata`);
      }
      return;
    }
    
    // Handle JSON messages (string)
    if (typeof data === 'string') {
      try {
        const message = JSON.parse(data);
        console.log(`[FileTransfer ${config.role}] Parsed message:`, message);
        
        // Validate message structure
        if (!isValidFileTransferMessage(message)) {
          console.error(`[FileTransfer ${config.role}] Invalid message structure:`, message);
          return;
        }
        
        if (message.type === 'file-start') {
          const { fileName, fileSize, transferId } = message;
          console.log(`[FileTransfer ${config.role}] File transfer started:`, { fileName, fileSize, transferId });
          
          // Validate fileSize
          if (typeof fileSize !== 'number' || fileSize <= 0) {
            console.error(`[FileTransfer ${config.role}] Invalid fileSize:`, fileSize);
            setTransferProgress(prev => prev ? { ...prev, status: 'error', error: 'Invalid file size' } : null);
            return;
          }
          
          console.log(`[FileTransfer ${config.role}] Creating transferProgress with fileName: ${fileName}`);
          setTransferProgress({
            fileName,
            fileSize,
            bytesTransferred: 0,
            percentage: 0,
            status: 'transferring'
          });
          console.log(`[FileTransfer ${config.role}] Setting receivedFileName to: ${fileName}`);
          setReceivedFileName(fileName);
          
          // Store filename for later use (in case transferProgress becomes null)
          if (config.role === 'client') {
            streamingMetadataRef.current.set(transferId, { fileName, fileSize, transferId });
          }
          
          // Calculate total chunks from file size
          const totalChunks = Math.ceil(fileSize / STREAM_CHUNK_SIZE);
          
          // Initialize streaming state
          streamingChunksRef.current.set(transferId, {
            chunks: new Array(totalChunks),
            totalChunks: totalChunks,
            receivedChunks: 0
          });
          
          console.log(`[FileTransfer ${config.role}] Initialized streaming state:`, {
            transferId,
            fileSize,
            totalChunks,
            chunkSize: STREAM_CHUNK_SIZE
          });
          
          // For client, set up storage based on file size and browser support
          if (config.role === 'client') {
            const isLargeFile = fileSize >= LARGE_FILE_THRESHOLD;
            const hasFS = hasFileSystemAccess();
            
            if (isLargeFile) {
              if (hasFS) {
                try {
                  console.log(`[FileTransfer Client] Large file detected (${Math.round(fileSize / 1024 / 1024)}MB), using File System Access API`);
                  console.log(`[FileTransfer Client] Original filename: ${fileName}`);
                  const fileHandle = await (window as any).showSaveFilePicker({
                    suggestedName: fileName,
                    types: [{
                      description: 'All Files',
                      accept: { '*/*': [] }
                    }]
                  });
                  console.log(`[FileTransfer Client] File handle name: ${fileHandle.name}`);
                  
                  const writable = await fileHandle.createWritable();
                  streamingWritersRef.current.set(transferId, writable);
                  setReceivedFileHandle(fileHandle);
                  console.log(`[FileTransfer Client] Created file handle for streaming large file`);
                } catch (error) {
                  console.error(`[FileTransfer Client] User cancelled file save or error:`, error);
                  setTransferProgress(prev => prev ? { ...prev, status: 'error', error: 'User cancelled file save' } : null);
                  return;
                }
              } else {
                // Warn user about memory usage
                const sizeInMB = Math.round(fileSize / 1024 / 1024);
                const proceed = confirm(`Large file detected (${sizeInMB}MB). This will use significant RAM as your browser doesn't support direct disk streaming. Continue?`);
                if (!proceed) {
                  console.log(`[FileTransfer Client] User cancelled large file transfer`);
                  setTransferProgress(prev => prev ? { ...prev, status: 'error', error: 'User cancelled large file transfer' } : null);
                  return;
                }
                console.log(`[FileTransfer Client] User accepted large file transfer to memory`);
              }
            } else {
              console.log(`[FileTransfer Client] Small file (${Math.round(fileSize / 1024)}KB), using memory storage`);
            }
          }
        } else if (message.type === 'file-chunk') {
          const { transferId, chunkIndex, totalChunks, data: chunkData } = message;
          console.log(`[FileTransfer ${config.role}] Received chunk metadata ${chunkIndex + 1}/${totalChunks} for transfer ${transferId}`, {
            chunkDataLength: chunkData?.length,
            chunkDataType: typeof chunkData,
            isArray: Array.isArray(chunkData)
          });
          
          // Store chunk metadata for binary data processing
          if (chunkData === undefined) {
            // This is a metadata-only message, store it for the next binary message
            pendingChunkMetadataRef.current = {
              chunkIndex,
              totalChunks,
              transferId
            };
            console.log(`[FileTransfer ${config.role}] Stored chunk metadata, waiting for binary data`);
            return;
          }
          
          const chunkUint8 = new Uint8Array(chunkData);
          const streamingState = streamingChunksRef.current.get(transferId);
          
          if (streamingState) {
            streamingState.chunks[chunkIndex] = chunkUint8;
            streamingState.totalChunks = totalChunks;
            streamingState.receivedChunks++;
            
            console.log(`[FileTransfer ${config.role}] Streaming state updated:`, {
              transferId,
              chunkIndex,
              totalChunks,
              receivedChunks: streamingState.receivedChunks,
              chunksArrayLength: streamingState.chunks.length
            });
            
            console.log(`[FileTransfer ${config.role}] About to process chunk...`);
            
            // Write chunk directly to file system (client only, for large files)
            if (config.role === 'client') {
              const writer = streamingWritersRef.current.get(transferId);
              
              if (writer) {
                try {
                  await writer.write(chunkUint8);
                  console.log(`[FileTransfer Client] Wrote chunk ${chunkIndex + 1} to disk (File System Access)`);
                } catch (error) {
                  console.error(`[FileTransfer Client] Failed to write chunk:`, error);
                }
              } else {
                console.log(`[FileTransfer Client] Storing chunk ${chunkIndex + 1} in memory`);
              }
            }
            
            console.log(`[FileTransfer ${config.role}] Finished writing chunk, about to update progress...`);
            
            // Update progress (throttled)
            updateProgressThrottled(prev => {
              if (!prev) return null;
              const chunkSize = chunkUint8.length; // Use the actual chunk size
              const newBytesTransferred = prev.bytesTransferred + chunkSize;
              const percentage = Math.round((newBytesTransferred / prev.fileSize) * 100);
              
              console.log(`[FileTransfer ${config.role}] Progress update:`, {
                chunkSize,
                newBytesTransferred,
                fileSize: prev.fileSize,
                percentage
              });
              
              return {
                ...prev,
                bytesTransferred: newBytesTransferred,
                percentage
              };
            });
            
            console.log(`[FileTransfer ${config.role}] About to check completion...`);
            
            // Check if all chunks received
            console.log(`[FileTransfer ${config.role}] Checking completion:`, {
              receivedChunks: streamingState.receivedChunks,
              totalChunks: streamingState.totalChunks,
              isComplete: streamingState.receivedChunks === streamingState.totalChunks
            });
            
            if (streamingState.receivedChunks === streamingState.totalChunks) {
              console.log(`[FileTransfer ${config.role}] Main completion check triggered:`, {
                receivedChunks: streamingState.receivedChunks,
                totalChunks: streamingState.totalChunks,
                transferId,
                role: config.role
              });
              
              // Validate chunk integrity before finalizing
              const missingChunks: number[] = [];
              for (let i = 0; i < streamingState.totalChunks; i++) {
                if (streamingState.chunks[i] === undefined) {
                  missingChunks.push(i);
                }
              }
              
              if (missingChunks.length > 0) {
                console.error(`[FileTransfer ${config.role}] Missing chunks detected:`, missingChunks);
          const errorMessage = `Missing ${missingChunks.length} chunks: ${missingChunks.join(', ')}`;
          setTransferProgress(prev => prev ? { 
            ...prev, 
            status: 'error', 
            error: errorMessage 
          } : null);
          
          // Call error callback
          if (config.onError) {
            config.onError(errorMessage);
          }
                return;
              }
              console.log(`[FileTransfer ${config.role}] All chunks received, finalizing file...`);
              
              if (config.role === 'client') {
                const writer = streamingWritersRef.current.get(transferId);
                
                if (writer) {
                  // File System Access API - large file saved to disk
                  try {
                    await writer.close();
                    console.log(`[FileTransfer Client] Large file saved to disk successfully (File System Access)`);
                    streamingWritersRef.current.delete(transferId);
                    setReceivedFileName(fileHandle.name || transferProgress?.fileName || 'received_file');
                    setReceivedFileHandle(null); // File was saved to disk, not in memory
                  } catch (error) {
                    console.error(`[FileTransfer Client] Failed to close file:`, error);
                  }
                } else {
                  // Small file or unsupported browser - create blob
                  const allChunks = streamingState.chunks.filter(chunk => chunk !== undefined);
                  const mimeType = getMimeType(transferProgress?.fileName || '');
                  const fileBlob = new Blob(allChunks as BlobPart[], { type: mimeType });
                  setReceivedFile(fileBlob);
                  console.log(`[FileTransfer Client] File assembled in memory`);
                }
              } else {
                // For host, create blob for display purposes only (should not happen)
                const allChunks = streamingState.chunks.filter(chunk => chunk !== undefined);
                const mimeType = getMimeType(transferProgress?.fileName || '');
                const fileBlob = new Blob(allChunks as BlobPart[], { type: mimeType });
                setReceivedFile(fileBlob);
              }
              
              streamingChunksRef.current.delete(transferId);
              
              setTransferProgress(prev => prev ? { ...prev, status: 'completed' } : null);
            }
          }
        } else if (message.type === 'file-error') {
          const { transferId, error } = message;
          console.error(`[FileTransfer ${config.role}] File transfer error:`, { transferId, error });
          
          // Clean up streaming state
          const writer = streamingWritersRef.current.get(transferId);
          
          if (writer) {
            try {
              await writer.close();
            } catch (e) {
              console.error('Error closing writer on error:', e);
            }
            streamingWritersRef.current.delete(transferId);
          }
          
          streamingChunksRef.current.delete(transferId);
          
          const resolver = fileResolversRef.current.get(transferId);
          if (resolver) {
            resolver.reject(new Error(error));
            fileResolversRef.current.delete(transferId);
          }
          setTransferProgress(prev => prev ? { ...prev, status: 'error', error } : null);
        } else if (message.type === 'request-chunks') {
          console.log(`[FileTransfer ${config.role}] Received chunk request:`, message);
          // This will be handled by the host to resend requested chunks
          // The actual resending logic will be implemented in the sendFile functions
        } else {
          console.log(`[FileTransfer ${config.role}] Unknown message type:`, message.type);
        }
      } catch (error) {
        console.error(`[FileTransfer ${config.role}] Error parsing file transfer message:`, error, 'Raw data:', data);
      }
    } else {
      console.log(`[FileTransfer ${config.role}] Received non-string data (not a file transfer message):`, data);
    }
  }, [config.role]);

  const hostPeer = useWebRTCHostPeer({
    ...config,
    onChannelMessage: handleFileChunk,
  });

  const clientPeer = useWebRTCClientPeer({
    ...config,
    onChannelMessage: handleFileChunk,
  });

  const activePeer = config.role === 'host' ? hostPeer : clientPeer;

  // Request missing chunks mechanism
  const requestMissingChunks = useCallback((transferId: string, missingChunks: number[]) => {
    if (config.role === 'client' && missingChunks.length > 0) {
      console.log(`[FileTransfer ${config.role}] Requesting missing chunks:`, missingChunks);
      
      const requestMessage = JSON.stringify({
        type: 'request-chunks',
        transferId,
        missingChunks
      });
      
      clientPeer?.send(requestMessage);
    }
  }, [config.role, clientPeer]);

  // Process retry queue function
  const processRetryQueue = useCallback(async (transferId: string, file: File, clientId?: string) => {
    const retries = Array.from(retryQueueRef.current.entries())
      .filter(([key]) => key.startsWith(transferId))
      .map(([key, retryInfo]) => ({ key, ...retryInfo }));
    
    if (retries.length === 0) return;
    
    logger.log(`Processing ${retries.length} retries for transfer ${transferId}`);
    
    for (const retry of retries) {
      if (retry.retryCount > retry.maxRetries) {
        logger.error(`Max retries exceeded for chunk ${retry.chunkIndex}`);
        retryQueueRef.current.delete(retry.key);
        continue;
      }
      
      try {
        // Retry sending the chunk
        const arrayBuffer = await file.arrayBuffer();
        const uint8Array = new Uint8Array(arrayBuffer);
        const start = retry.chunkIndex * STREAM_CHUNK_SIZE;
        const end = Math.min(start + STREAM_CHUNK_SIZE, file.size);
        const chunk = uint8Array.slice(start, end);
        
        // Send chunk metadata
        const chunkMetadata = JSON.stringify({
          type: 'file-chunk',
          transferId,
          chunkIndex: retry.chunkIndex,
          totalChunks: Math.ceil(file.size / STREAM_CHUNK_SIZE)
        });
        
        if (clientId) {
          hostPeer?.send(chunkMetadata, clientId);
          hostPeer?.send(chunk.buffer, clientId);
        } else {
          hostPeer?.send(chunkMetadata);
          hostPeer?.send(chunk.buffer);
        }
        
        console.log(`[FileTransfer ${config.role}] Retried chunk ${retry.chunkIndex} (attempt ${retry.retryCount})`);
        
        // Remove from retry queue on successful send
        retryQueueRef.current.delete(retry.key);
        
        // Add delay between retries
        await new Promise(resolve => setTimeout(resolve, RETRY_DELAY));
        
      } catch (error) {
        logger.error(`Retry failed for chunk ${retry.chunkIndex}:`, error);
      }
    }
  }, [logger, hostPeer]);

  // Simple fallback sending with adaptive pacing
  const sendFileSimple = useCallback(async (file: File, clientId: string | undefined, transferId: string, totalChunks: number) => {
    console.log(`[FileTransfer Host] Using adaptive pacing for ${totalChunks} chunks`);
    
    try {
      const arrayBuffer = await file.arrayBuffer();
      const uint8Array = new Uint8Array(arrayBuffer);
      
      console.log(`[FileTransfer Host] Starting to send ${totalChunks} chunks with adaptive pacing...`);
      
      // Get data channel for bufferedAmount monitoring
      let dataChannel = null;
      if (clientId) {
        const clientConn = (hostPeer as any).clientConnectionsRef?.current?.get(clientId);
        dataChannel = clientConn?.dc;
      } else {
        const clientConnections = (hostPeer as any).clientConnectionsRef?.current;
        if (clientConnections) {
          for (const [id, conn] of clientConnections) {
            if (conn.dc && conn.dc.readyState === 'open') {
              dataChannel = conn.dc;
              break;
            }
          }
        }
      }
      
      for (let i = 0; i < totalChunks; i++) {
        const start = i * STREAM_CHUNK_SIZE;
        const end = Math.min(start + STREAM_CHUNK_SIZE, file.size);
        const chunk = uint8Array.slice(start, end);
        
        // Send chunk metadata as JSON first
        const chunkMetadata = JSON.stringify({
          type: 'file-chunk',
          transferId,
          chunkIndex: i,
          totalChunks
        });
        
        console.log(`[FileTransfer Host] Sending chunk ${i + 1}/${totalChunks} (${chunk.length} bytes)`);
        
        // Send metadata
        if (clientId) {
          hostPeer.send(chunkMetadata, clientId);
        } else {
          hostPeer.send(chunkMetadata);
        }
        
        // Send binary chunk data directly
        if (clientId) {
          hostPeer.send(chunk.buffer, clientId);
        } else {
          hostPeer.send(chunk.buffer);
        }
        
        // Update progress
        setTransferProgress(prev => {
          if (!prev) return null;
          const newBytesTransferred = prev.bytesTransferred + chunk.length;
          return {
            ...prev,
            bytesTransferred: newBytesTransferred,
            percentage: Math.round((newBytesTransferred / prev.fileSize) * 100)
          };
        });
        
        // Simplified backpressure mechanism
        if (dataChannel && dataChannel.bufferedAmount > 1024 * 1024) { // 1MB buffer limit
          await new Promise(resolve => {
            const checkBuffer = () => {
              if (dataChannel.bufferedAmount < 1024 * 1024 * 0.5) {
                resolve(undefined);
              } else {
                setTimeout(checkBuffer, 50);
              }
            };
            checkBuffer();
          });
        } else {
          // Small delay to prevent overwhelming the data channel
          await new Promise(resolve => setTimeout(resolve, 5));
        }
      }
      
      console.log(`[FileTransfer Host] Simple file transfer completed successfully - sent ${totalChunks} chunks`);
      setTransferProgress(prev => prev ? { ...prev, status: 'completed' } : null);
      setIsTransferring(false);
      
    } catch (error) {
      console.error(`[FileTransfer Host] Simple file transfer failed:`, error);
      setTransferProgress(prev => prev ? { 
        ...prev, 
        status: 'error', 
        error: error instanceof Error ? error.message : 'Unknown error' 
      } : null);
      setIsTransferring(false);
    }
  }, [hostPeer]);

  const sendFile = useCallback(async (file: File, clientId?: string) => {
    if (config.role !== 'host') {
      throw new Error('sendFile can only be called on host');
    }

    const transferId = `transfer_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    const totalChunks = Math.ceil(file.size / STREAM_CHUNK_SIZE);
    
    console.log(`[FileTransfer Host] Starting streaming file transfer:`, {
      fileName: file.name,
      fileSize: file.size,
      totalChunks,
      transferId,
      clientId: clientId || 'all clients'
    });
    
    setTransferProgress({
      fileName: file.name,
      fileSize: file.size,
      bytesTransferred: 0,
      percentage: 0,
      status: 'transferring'
    });
    
    setIsTransferring(true);

    try {
      // Send file start message
      const startMessage = JSON.stringify({
        type: 'file-start',
        fileName: file.name,
        fileSize: file.size,
        transferId
      });
      
      console.log(`[FileTransfer Host] Sending file start message:`, startMessage);
      
      if (clientId) {
        hostPeer.send(startMessage, clientId);
        console.log(`[FileTransfer Host] Sent start message to client ${clientId}`);
      } else {
        hostPeer.send(startMessage);
        console.log(`[FileTransfer Host] Sent start message to all clients`);
      }

      // Get the data channel for backpressure handling
      let dataChannel = null;
      
      console.log(`[FileTransfer Host] Looking for data channel:`, {
        clientId: clientId || 'broadcast',
        connectedClients: hostPeer.connectedClients,
        clientConnections: hostPeer.clientConnections
      });
      
      if (clientId) {
        // Get specific client's data channel
        const clientConn = (hostPeer as any).clientConnectionsRef?.current?.get(clientId);
        console.log(`[FileTransfer Host] Client connection for ${clientId}:`, {
          exists: !!clientConn,
          hasDC: !!clientConn?.dc,
          dcState: clientConn?.dc?.readyState
        });
        dataChannel = clientConn?.dc;
      } else {
        // For broadcast, get the first available data channel
        const clientConnections = (hostPeer as any).clientConnectionsRef?.current;
        console.log(`[FileTransfer Host] Available client connections:`, clientConnections ? Array.from(clientConnections.keys()) : 'none');
        
        if (clientConnections) {
          for (const [id, conn] of clientConnections) {
            console.log(`[FileTransfer Host] Checking connection ${id}:`, {
              hasDC: !!conn.dc,
              dcState: conn.dc?.readyState
            });
            if (conn.dc && conn.dc.readyState === 'open') {
              dataChannel = conn.dc;
              console.log(`[FileTransfer Host] Using data channel from client ${id}`);
              break;
            }
          }
        }
      }

      if (!dataChannel) {
        console.warn(`[FileTransfer Host] Data channel not available, falling back to simple sending`);
        // Fallback to simple sending without backpressure
        await sendFileSimple(file, clientId, transferId, totalChunks);
        return;
      }

      for (let i = 0; i < totalChunks; i++) {
        const start = i * STREAM_CHUNK_SIZE;
        const end = Math.min(start + STREAM_CHUNK_SIZE, file.size);
        const chunk = file.slice(start, end);

        const chunkArrayBuffer = await chunk.arrayBuffer();
        const chunkUint8 = new Uint8Array(chunkArrayBuffer);

        // Send chunk metadata as JSON first
        const chunkMetadata = JSON.stringify({
          type: 'file-chunk',
          transferId,
          chunkIndex: i,
          totalChunks
        });

        console.log(`[FileTransfer Host] Sending chunk ${i + 1}/${totalChunks} (${chunkUint8.length} bytes)`);

        // Send metadata
        if (clientId) {
          hostPeer.send(chunkMetadata, clientId);
        } else {
          hostPeer.send(chunkMetadata);
        }

        // Send binary chunk data directly
        if (clientId) {
          hostPeer.send(chunkArrayBuffer, clientId);
        } else {
          hostPeer.send(chunkArrayBuffer);
        }

        // Update progress
        setTransferProgress(prev => {
          if (!prev) return null;
          const newBytesTransferred = prev.bytesTransferred + chunkUint8.length;
          return {
            ...prev,
            bytesTransferred: newBytesTransferred,
            percentage: Math.round((newBytesTransferred / prev.fileSize) * 100)
          };
        });

        // Adaptive pacing based on bufferedAmount
        if (dataChannel.bufferedAmount > 1024 * 1024) { // 1MB buffer limit
          await new Promise(resolve => {
            const listener = () => {
              dataChannel.removeEventListener('bufferedamountlow', listener);
              resolve(undefined);
            };
            dataChannel.addEventListener('bufferedamountlow', listener);
          });
        }
      }

      console.log(`[FileTransfer Host] File transfer completed successfully`);
      setTransferProgress(prev => prev ? { ...prev, status: 'completed' } : null);
      setIsTransferring(false);
      
    } catch (error) {
      console.error(`[FileTransfer Host] File transfer failed:`, error);
      
      const errorMessage = JSON.stringify({
        type: 'file-error',
        transferId,
        error: error instanceof Error ? error.message : 'Unknown error'
      });
      
      if (clientId) {
        hostPeer.send(errorMessage, clientId);
      } else {
        hostPeer.send(errorMessage);
      }
      
      setTransferProgress(prev => prev ? { 
        ...prev, 
        status: 'error', 
        error: error instanceof Error ? error.message : 'Unknown error' 
      } : null);
      setIsTransferring(false);
    }
  }, [config.role, hostPeer]);

  const clearTransfer = useCallback(async () => {
    console.log(`[FileTransfer ${config.role}] Clearing transfer state`);
    setTransferProgress(null);
    setIsTransferring(false);
    setReceivedFile(null);
    setReceivedFileName(null);
    setReceivedFileHandle(null);
    
    // Close any open file writers
    streamingWritersRef.current.forEach(async (writer, transferId) => {
      try {
        await writer.close();
      } catch (error) {
        console.error(`Error closing writer for ${transferId}:`, error);
      }
    });
    
    streamingWritersRef.current.clear();
    streamingChunksRef.current.clear();
    fileResolversRef.current.clear();
    streamingMetadataRef.current.clear();
    
    // Clear pending metadata
    pendingChunkMetadataRef.current = null;
    
    // Clear retry queue
    retryQueueRef.current.clear();
    
    // Reset progress update throttle
    lastProgressUpdateRef.current = 0;
  }, [config.role]);

  const cancelTransfer = useCallback((transferId?: string) => {
    console.log(`[FileTransfer ${config.role}] Cancelling transfer:`, transferId || 'current');
    
    if (config.role === 'host') {
      // Send cancellation message to clients
      const cancelMessage = JSON.stringify({
        type: 'file-error',
        transferId: transferId || 'current',
        error: 'Transfer cancelled by host'
      });
      
      if (hostPeer) {
        hostPeer.send(cancelMessage);
      }
    }
    
    // Clear transfer state
    setTransferProgress(prev => prev ? { 
      ...prev, 
      status: 'error', 
      error: 'Transfer cancelled' 
    } : null);
    
    // Clear all state
    clearTransfer();
  }, [config.role, hostPeer, clearTransfer]);

  return {
    sendFile,
    cancelTransfer,
    receivedFile,
    receivedFileName,
    receivedFileHandle,
    transferProgress,
    isTransferring,
    clearTransfer,
    onProgress: config.onProgress,
    onComplete: config.onComplete,
    onError: config.onError,
    connectionState: activePeer.connectionState,
    dataChannelState: activePeer.dataChannelState,
    createOrEnsureConnection: activePeer.createOrEnsureConnection,
    close: activePeer.close,
    disconnect: activePeer.disconnect,
    role: activePeer.role,
    peerId: activePeer.peerId,
    connectedClients: 'connectedClients' in activePeer ? activePeer.connectedClients : undefined,
    clientConnections: 'clientConnections' in activePeer ? activePeer.clientConnections : undefined,
  };
}